tags:: blog, draft

- There is a lot of information about the [[alignment]] problem on the Internet. Let me mention just one thing: The [[alignment]] within individuals and organizations does not receive sufficient [[attention]], e.g.
  * What a person pursues, and what is good for them.
  * What people want, and to what they devote [[attention]] and [effort](https://www.smbc-comics.com/comic/2013-08-04).
- In philosophy, personal alignment has received significant coverage:
  * Plato: The chariot, charioteer, and white and dark horses.
  * Freud: [[ego]], superego, id.
  * Nietzsche: Apollonian and Dionysian.
  * And probably anyone trying to analyse the mind, and any conflict arising in it, with conflict being “not-alignment.”
- Lack of internal [[alignment]] may result in people harming themselves, e.g. addictions.
- An analogous lack of internal [[alignment]] may cause organisations, companies, and teams, to act against their own interests, and those of the parent organisation, e.g. [[golden KPI]] .
- AI [[alignment]] is an interesting topic, for a number of reasons, including:
  * It needs to be super-human much earlier than any other “features” of the AI, especially considering how low the human bar is in this case (see previous examples).
  * In a [[TDD]] approach, the test for [[alignment]] precedes the [[alignment]], and the [[alignment]] must precede the intelligence.
  * In a generator-discriminator [[context]], even if the generator cannot produce an aligned solution, if the discriminator can identify the unaligned solutions (recall ≺ precision), that may be enough for safety.
-
-