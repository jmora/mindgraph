-
- In a matter, quantity beats [[quality]].
- It is the result of an [[asymmetric two-sided problem]]
  * [[quality]] may be negative.
  * quantity cannot be negative.
  $$result = quality \cdot quantity$$
- Normally the bitterness reason is:
  * We would prefer [[quality]] to be the most relevant part.
  * Quantity seems to be more relevant.
  Related: repugnant conclusion.
- It is a multiplication, both are similarly relevant (when positive), but:
  * The [[quality]] range is small and assumed, or hard to perceive and ascribed to luck or randomness.
  * The quantity aspect is more salient, resulting in salience bias.
  #speculation bitter lessons are the result of bias and [[delusion]].
  
  Note that [[quality]] is likely to be prioritized and become implicit. Reasons for prioritizing [[quality]]:
  * [[Subjective]] preference.
  * Priority in ensuring [[quality]] before increasing resource investment.
  * Possibility of negative values: negative return.
- For new participants, bitter lessons are a potential trap:
  * The [[quality]] is implicit knowledge, assumed, and not acquired.
  * Following the bitter lesson, quantity is prioritized.
  * Extraordinary quantities of a negative [[quality]] have a (extraordinarily) negative outcome.
  Related: [[sunk-cost fallacy]], [[opportunity cost]], [[underthinking]], [[malinvestment]].
- There are many potential bitter lessons in machine learning and AI:
	- Human knowledge vs computation (original bitter lesson by [Rich Sutton](http://www.incompleteideas.net/IncIdeas/BitterLesson.html))
	- Fancy theories vs experiments ([François Chollet](https://twitter.com/fchollet/status/1611286048084041728))
		- Note: do not confuse a theorem with a working hypothesis. Both may be considered theoretical, but:
		  * Proven theorems provide a solid foundation for incremental iteration. ("standing on the shoulders of giants")
		  * Working hypotheses are often disposable and when proven false they may cause a return to square one (~[[Sisyphos curse]])
		- Note: "airplanes do not flap their wings." Do not confuse the human brain with intelligence, nor vice versa.
	- Data quantity vs data [[quality]], big data vs small data, curation vs aggregation.
	- Possibly related:
		- Model-centric vs data-centric ([Andrew Ng](https://twitter.com/AndrewYNg/status/1407042299637403652))
		- Model size vs token set size ([Hoffmann et al](https://twitter.com/DeepMind/status/1513901600968003594))
		- OpenCyc vs LLMs
-
-
- Example: bad products, good marketing.
	- A bad product with good marketing may win over a good product with bad marketing.
	- Winners write history: history is rewritten (by marketing) as: “a good product won to a bad product.”
- First mover advantage.
	- A bad product with bad foundations moves first and dominates an area.
	- New entrants have to fight an uphill battle against the incumbent, which has more traction, resources, visibility,…
	- Foundations now need to be ~10x better to have a chance, possibly 100x.
	- Example: JavaScript is often criticized (especially type casting, e.g. equality is not transitive due to type casting). But rather than anything replacing JavaScript in the frontend, it has such a strong hold of the frontend that got a significant popularity in the backend.
-
-
-