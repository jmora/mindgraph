-
- If a solution space is not properly explored, the search for a solution may be considered prematurely failed, i.e. persistence would result in success
- ((63bfe277-d00c-4f26-9085-0b718262f411))
- Usually, the way to avoid [[premature fail risk]] is not exploring faster nor exploring longer, but exploring better
	- exploration is [multiplicative]([[multiplicative system]])
	- [[strategy]] and [[situational awareness]] are key to reduce the “persistence requirements” to affordable levels
	- Related: [[fail fast]], [[situational awareness]], [[embracing ignorance]], [[exhaust theory]], [[locality risk]], [[infinite dead end]]
- [[premature fail risk]] does not have a time limit, e.g. in an infinite search space, branches that do not contain the solution may be explored indefinitely
  * Arguably, the search for AGI started with homunculi and golems, but infinite centuries of alchemy studies would not result in AGI
  * The search for AGI is not considered failed. However, scaling deep learning may be a similar [[infinite dead end]] (time might tell)
- In the next following years we will see premature fail of many initiatives
  collapsed:: true
  * Many companies will attempt to use $$x$$ to solve problems that have already been solved with $$x$$, and fail at that, concluding that $$x$$ does not work, or does not work for them
  * In this [[context]] $$x$$ may be: AI, non-hierarchical structure, distributed leadership, [[outcome]]-driven, remote learning,…
	- {{tweet https://twitter.com/swardley/status/1478702842764566537}}
- > “When people say you can't do it - that it's impossible - never lose hope. Just because they couldn't doesn't mean you can't.” — David Copperfield (maybe) #quote
-